{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "# Get the absolute path to the parent directory of the notebook\n",
    "notebook_dir = os.path.abspath(r'C:/Users/Abdulaziz/Desktop/10 Academy/TellCo mobile service provider/notebooks')\n",
    "# Get the absolute path to the parent directory of the notebook's parent directory\n",
    "project_dir = os.path.dirname(notebook_dir)\n",
    "# Add the project directory to the Python path\n",
    "sys.path.append(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import missing_values_table, convert_bytes_to_megabytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/Week2_challenge_data_source(CSV).csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_df = missing_values_table(df)\n",
    "print(\"Missing Values in df:\")\n",
    "print(missing_values_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x'] = convert_bytes_to_megabytes(df, 'HTTP DL (Bytes)')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.clean import clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('cleandata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Overview analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_handsets = df_clean['Handset Type'].value_counts().head(10)\n",
    "\n",
    "print(top_10_handsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a bar plot\n",
    "\n",
    "top_10_handsets.plot(kind='barh', color='brown')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Top 10 Handsets Used by Customers')\n",
    "plt.xlabel('Handset')\n",
    "plt.ylabel('Number of Customers')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_handsets = df_clean['Handset Manufacturer'].value_counts().head(3)\n",
    "\n",
    "print(top_3_handsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a bar plot\n",
    "\n",
    "top_3_handsets.plot(kind='pie')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Top 3 Handset Manufacturers Used by Customers')\n",
    "plt.xlabel('Handset')\n",
    "plt.ylabel('Number of Customers')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_manufacturers = df_clean['Handset Manufacturer'].value_counts().head(3).index\n",
    "\n",
    "# For each of the top 3 manufacturers, get the top 5 handsets\n",
    "for manufacturer in top_3_manufacturers:\n",
    "    print(f\"Top 5 handsets for {manufacturer}:\")\n",
    "    top_5_handsets = df_clean[df_clean['Handset Manufacturer'] == manufacturer]['Handset Type'].value_counts().head(5)\n",
    "    print(top_5_handsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get the top 5 handsets for each of the top 3 manufacturers\n",
    "top_handsets = {}\n",
    "for manufacturer in top_3_manufacturers:\n",
    "    top_5_handsets = df_clean[df_clean['Handset Manufacturer'] == manufacturer]['Handset Type'].value_counts().head(5)\n",
    "    top_handsets[manufacturer] = top_5_handsets\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "top_handsets_df = pd.DataFrame(top_handsets)\n",
    "\n",
    "# Create a grouped bar chart\n",
    "top_handsets_df.plot(kind='barh')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Top 5 Handsets for Each of the Top 3 Manufacturers')\n",
    "plt.xlabel('Handset Type')\n",
    "plt.ylabel('Number of Handsets')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sessions = df_clean.groupby('MSISDN/Number')['Bearer Id'].nunique()\n",
    "\n",
    "# Aggregate per user the session duration\n",
    "user_session_duration = df_clean.groupby('MSISDN/Number')['Dur. (ms)'].sum()\n",
    "\n",
    "# Aggregate per user the total download (DL) and upload (UL) data\n",
    "user_total_DL = df_clean.groupby('MSISDN/Number')['Total DL (Bytes)'].sum()\n",
    "user_total_UL = df_clean.groupby('MSISDN/Number')['Total UL (Bytes)'].sum()\n",
    "\n",
    "# Aggregate per user the total data volume (in Bytes) during this session for each application\n",
    "user_total_data_vol = df_clean.groupby('MSISDN/Number')[['Social Media DL (Bytes)', 'Social Media UL (Bytes)', 'Youtube DL (Bytes)', 'Youtube UL (Bytes)', 'Netflix DL (Bytes)', 'Netflix UL (Bytes)', 'Google DL (Bytes)', 'Google UL (Bytes)', 'Email DL (Bytes)', 'Email UL (Bytes)', 'Gaming DL (Bytes)', 'Gaming UL (Bytes)', 'Other DL (Bytes)', 'Other UL (Bytes)']].sum()\n",
    "\n",
    "# Print the aggregated information\n",
    "print(\"Number of xDR sessions per user:\\n\", user_sessions)\n",
    "print(\"\\nSession duration per user:\\n\", user_session_duration)\n",
    "print(\"\\nTotal download (DL) data per user:\\n\", user_total_DL)\n",
    "print(\"\\nTotal upload (UL) data per user:\\n\", user_total_UL)\n",
    "print(\"\\nTotal data volume (in Bytes) during this session for each application per user:\\n\", user_total_data_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantitative_columns = ['Bearer Id', 'Start ms', 'End ms', 'Dur. (ms)', 'IMSI', 'MSISDN/Number', 'IMEI', 'Avg RTT DL (ms)', 'Avg RTT UL (ms)', 'Avg Bearer TP DL (kbps)', 'Avg Bearer TP UL (kbps)', 'DL TP < 50 Kbps (%)', '50 Kbps < DL TP < 250 Kbps (%)', '250 Kbps < DL TP < 1 Mbps (%)', 'DL TP > 1 Mbps (%)', 'UL TP < 10 Kbps (%)', '10 Kbps < UL TP < 50 Kbps (%)', '50 Kbps < UL TP < 300 Kbps (%)', 'UL TP > 300 Kbps (%)', 'Activity Duration DL (ms)', 'Activity Duration UL (ms)', 'Dur. (ms).1', 'Social Media DL (Bytes)', 'Social Media UL (Bytes)', 'Google DL (Bytes)', 'Google UL (Bytes)', 'Email DL (Bytes)', 'Email UL (Bytes)', 'Youtube DL (Bytes)', 'Youtube UL (Bytes)', 'Netflix DL (Bytes)', 'Netflix UL (Bytes)', 'Gaming DL (Bytes)', 'Gaming UL (Bytes)', 'Other DL (Bytes)', 'Other UL (Bytes)', 'Total UL (Bytes)', 'Total DL (Bytes)']\n",
    "\n",
    "# Perform univariate analysis\n",
    "for column in quantitative_columns:\n",
    "    print(f\"\\nAnalysis for {column}:\")\n",
    "    print(f\"Mean: {df[column].mean()}\")\n",
    "    print(f\"Median: {df[column].median()}\")\n",
    "    print(f\"Mode: {df[column].mode()[0]}\")\n",
    "    print(f\"Variance: {df[column].var()}\")\n",
    "    print(f\"Standard Deviation: {df[column].std()}\")\n",
    "    print(f\"Range: {df[column].max() - df[column].min()}\")\n",
    "    print(f\"IQR: {df[column].quantile(0.75) - df[column].quantile(0.25)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# List of numerical columns\n",
    "\n",
    "\n",
    "# List of categorical columns\n",
    "categorical_columns = ['Handset Manufacturer', 'Handset Type']\n",
    "\n",
    "# For each numerical column, create a histogram and a boxplot\n",
    "for column in quantitative_columns[:10]:\n",
    "   \n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(df_clean[column], bins=30, kde=True, color='brown')\n",
    "    plt.title(f'Histogram of {column}')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(x=df_clean[column])\n",
    "    plt.title(f'Boxplot of {column}')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# For each categorical column, create a bar plot\n",
    "for column in categorical_columns[:10]:\n",
    "    \n",
    "    df[column].value_counts().head(10).plot(kind='bar',color='brown')\n",
    "    plt.title(f'Bar plot of {column}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "#Bivariate \n",
    "# Calculate total DL+UL data\n",
    "df_clean['Total Data'] = df_clean['Total DL (Bytes)'] + df_clean['Total UL (Bytes)']\n",
    "\n",
    "# List of applications\n",
    "applications = ['Social Media DL (Bytes)', 'Social Media UL (Bytes)', 'Google DL (Bytes)', 'Google UL (Bytes)', 'Email DL (Bytes)', 'Email UL (Bytes)', 'Youtube DL (Bytes)', 'Youtube UL (Bytes)', 'Netflix DL (Bytes)', 'Netflix UL (Bytes)', 'Gaming DL (Bytes)', 'Gaming UL (Bytes)', 'Other DL (Bytes)', 'Other UL (Bytes)']\n",
    "\n",
    "# For each application, create a scatter plot with the total data\n",
    "for app in applications:\n",
    "    df_clean[30:35].plot(kind='scatter', x=app, y='Total Data')\n",
    "    plt.title(f'{app} vs Total Data')\n",
    "    plt.show()\n",
    "# Create decile classes based on the total duration\n",
    "\n",
    "df_clean['Decile Rank'] = pd.qcut(df_clean['Dur. (ms)'], 10, labels=False, duplicates='drop')\n",
    "\n",
    "\n",
    "# Get the top five decile classes\n",
    "top_five_deciles = df_clean[df_clean['Decile Rank'] >= 5]\n",
    "\n",
    "# Compute the total data (DL+UL) per decile class\n",
    "total_data_per_decile = top_five_deciles.groupby('Decile Rank')['Total Data'].sum()\n",
    "\n",
    "print(total_data_per_decile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['Social Media DL (Bytes)', 'Social Media UL (Bytes)', 'Google DL (Bytes)', 'Google UL (Bytes)', 'Email DL (Bytes)', 'Email UL (Bytes)', 'Youtube DL (Bytes)', 'Youtube UL (Bytes)', 'Netflix DL (Bytes)', 'Netflix UL (Bytes)', 'Gaming DL (Bytes)', 'Gaming UL (Bytes)', 'Other DL (Bytes)', 'Other UL (Bytes)']\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = df_clean[variables].corr()\n",
    "\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute the correlation matrix (assuming 'df' is your DataFrame)\n",
    "corr_matrix = df_clean[variables].corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True, square=True)\n",
    "\n",
    "# Set the title\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "\n",
    "# Select only the numeric columns\n",
    "numeric_columns = df_clean.select_dtypes(include=[np.number])\n",
    "\n",
    "# Standardize the features to have mean=0 and variance=1\n",
    "features_scaled = StandardScaler().fit_transform(numeric_columns)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()\n",
    "principalComponents = pca.fit_transform(features_scaled)\n",
    "\n",
    "# Convert array of principal components to a DataFrame\n",
    "principal_cleadf_clean = pd.DataFrame(data = principalComponents, columns = ['Principal Component ' + str(i) for i in range(1, len(numeric_columns.columns)+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Engagement analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_frequency = df_clean.groupby('MSISDN/Number')['Bearer Id'].count()\n",
    "session_duration = df_clean.groupby('MSISDN/Number')['Dur. (ms)'].sum()\n",
    "session_total_traffic = df_clean.groupby('MSISDN/Number')[['Total UL (Bytes)', 'Total DL (Bytes)']].sum()\n",
    "session_total_traffic['Total Traffic'] = session_total_traffic['Total UL (Bytes)'] + session_total_traffic['Total DL (Bytes)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_frequency.plot(kind='hist', rwidth=0.8)\n",
    "plt.title('Sessions Frequency')\n",
    "plt.xlabel('Number of Sessions')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_duration.plot(kind='box')\n",
    "plt.title('Session Duration')\n",
    "plt.ylabel('Duration (ms)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "session_total_traffic['Total Traffic'].plot(kind='hist', rwidth=0.8)\n",
    "plt.title('Session Total Traffic')\n",
    "plt.xlabel('Total Traffic (Bytes)')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "engagement_metrics = ['Bearer Id', 'Dur. (ms)', 'Total UL (Bytes)', 'Total DL (Bytes)']\n",
    "for metric in engagement_metrics:\n",
    "    top_10_customers = df_clean.groupby('MSISDN/Number')[metric].sum().nlargest(10)\n",
    "    print(f\"Top 10 customers for {metric}:\\n\", top_10_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "df_normalized = scaler.fit_transform(df_clean[engagement_metrics])\n",
    "\n",
    "# Apply k-means clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(df_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Compute the minimum, maximum, average & total non-normalized metrics for each cluster\n",
    "cluster_metrics = df_clean.groupby('Cluster')[engagement_metrics].agg(['min', 'max', 'mean', 'sum'])\n",
    "print(cluster_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['Social Media Data'] = df_clean['Social Media DL (Bytes)'] + df_clean['Social Media UL (Bytes)']\n",
    "df_clean['Google Data'] = df_clean['Google DL (Bytes)'] + df_clean['Google UL (Bytes)']\n",
    "df_clean['Email Data'] = df_clean['Email DL (Bytes)'] + df_clean['Email UL (Bytes)']\n",
    "df_clean['Youtube Data'] = df_clean['Youtube DL (Bytes)'] + df_clean['Youtube UL (Bytes)']\n",
    "df_clean['Netflix Data'] = df_clean['Netflix DL (Bytes)'] + df_clean['Netflix UL (Bytes)']\n",
    "df_clean['Gaming Data'] = df_clean['Gaming DL (Bytes)'] + df_clean['Gaming UL (Bytes)']\n",
    "df_clean['Other Data'] = df_clean['Other DL (Bytes)'] + df_clean['Other UL (Bytes)']\n",
    "\n",
    "# List of applications\n",
    "applications = ['Social Media Data', 'Google Data', 'Email Data', 'Youtube Data', 'Netflix Data', 'Gaming Data', 'Other Data']\n",
    "\n",
    "# For each application, find the top 10 most engaged users\n",
    "for app in applications:\n",
    "    top_10_users_app = df_clean.groupby('MSISDN/Number')[app].sum().nlargest(10)\n",
    "    print(f\"Top 10 most engaged users for {app}:\\n\", top_10_users_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_usage = df_clean[applications].sum()\n",
    "\n",
    "# Sort and select top 3 applications\n",
    "top_3_apps = total_data_usage.sort_values(ascending=False)[:3]\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_3_apps.plot(kind='bar', color='skyblue')\n",
    "plt.title('Top 3 Most Used Applications')\n",
    "plt.ylabel('Total Data (Bytes)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Determine the optimal number of clusters using the elbow method\n",
    "distortions = []\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k)\n",
    "    kmeanModel.fit(df_normalized)\n",
    "    distortions.append(kmeanModel.inertia_)\n",
    "\n",
    "plt.plot(K, distortions, 'bx-', color='red')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
